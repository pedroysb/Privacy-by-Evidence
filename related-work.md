[Back to index](https://pedroysb.github.io/Privacy-by-Evidence)

# Related Work

<p>To ensure privacy protection, we must take into account principles and guidelines about individuals’ privacy, such as the <em>Privacy by Design</em> (<em>PbD</em>) <span class="citation">(Cavoukian 2009)</span>. <em>PbD</em> consists in 7 foundational principles to be followed when developing systems that should take into account users privacy:</p>
<ol>
<li><p><strong>Proactive not Reactive; Preventative not Remedial</strong>: The <em>PbD</em> approach is characterized by proactive rather than reactive measures. It anticipates and prevents privacy invasive events before they happen. <em>PbD</em> does not wait for privacy risks to materialize, nor does it offer remedies for resolving privacy infractions once they have occurred – it aims to prevent them from occurring. In short, <em>PbD</em> comes before-the-fact, not after.</p></li>
<li><p><strong>Privacy as the Default Setting</strong>: <em>PbD</em> seeks to deliver the maximum degree of privacy by ensuring that personal data are automatically protected in any given IT system or business practice. If an individual does nothing, their privacy still remains intact. No action is required on the part of the individual to protect their privacy – it is built into the system, <em>by default</em>.</p></li>
<li><p><strong>Privacy Embedded into Design</strong>: <em>PbD</em> is embedded into the design and architecture of IT systems and business practices. It is not bolted on as an add-on, after the fact. The result is that privacy becomes an essential component of the core functionality being delivered. Privacy is integral to the system, without diminishing functionality.</p></li>
<li><p><strong>Full Functionality – Positive-Sum, not Zero-Sum</strong>: <em>PbD</em> seeks to accommodate all legitimate interests and objectives in a positive-sum “win-win” manner, not through a dated, zero-sum approach, where unnecessary trade-offs are made. <em>PbD</em> avoids the pretense of false dichotomies, such as privacy vs. security, demonstrating that it is possible to have both.</p></li>
<li><p><strong>End-to-End Security – Full Lifecycle Protection</strong>: <em>PbD</em>, having been embedded into the system prior to the first element of information being collected, extends securely throughout the entire lifecycle of the data involved – strong security measures are essential to privacy, from start to finish. This ensures that all data are securely retained, and then securely destroyed at the end of the process, in a timely fashion. Thus, <em>PbD</em> ensures cradle to grave, secure lifecycle management of information, end-to-end.</p></li>
<li><p><strong>Visibility and Transparency – Keep it Open</strong>: <em>PbD</em> seeks to assure all stakeholders that whatever the business practice or technology involved, it is in fact, operating according to the stated promises and objectives, subject to independent verification. Its component parts and operations remain visible and transparent, to users and providers alike.</p></li>
<li><p><strong>Respect for User Privacy – Keep it User-Centric</strong>: Above all, <em>PbD</em> requires architects and operators to keep the interests of the individual uppermost by offering such measures as strong privacy defaults, appropriate notice, and empowering user-friendly options.</p></li>
</ol>
<p>The definition of these principles alone are not enough. Gürses <em>et al.</em> <span class="citation">(Gurses, Troncoso, and Diaz 2011)</span> argue that while these principles are useful to guide development, they are still vague and leave many open questions on how to apply them in practice. For example, the fourth principle (Full Functionality – Positive-Sum, not Zero-Sum) classifies trade-offs as unnecessary because <em>PbD</em> seeks to accommodate the objectives in a “win-win” manner. However, there is no explanation and demonstration on how to achieve that. Through case studies, Gürses <em>et al</em>. demonstrate that there is not only one way to tackle privacy protection problems, and conclude that the development of a generalizable methodology is necessary. Our work acknowledges this and describes a methodology to ensure privacy preservation in various contexts.</p>
<p>The Nokia institute published a white paper <span class="citation">(<em>Privacy Engineering &amp; Assurance</em> 2014)</span> on how to use privacy protection policies. The paper states that there is a lack of privacy experts, so, a software engineering discipline called <em>Privacy Engineering &amp; Assurance</em> is proposed. This discipline aims to be a systematic approach in the implementation of the <em>PbD</em> principles, and yet, foster the birth of a new professional, the <em>Privacy Engineer</em>. Despite the relevance, the introduction to new topics and concepts on its own is not enough. We still need a detailed methodology to know how to organize the development workflow and to guide the implementation of privacy-friendly applications.</p>
<p>Ionescu <em>et al</em>. <span class="citation">(Ionescu and Engelbrecht 2016)</span> propose an argumentative structure to privacy cases, matching the privacy-protection goals to human and organizational privacy concerns. They seek to analyse privacy risks from the perspectives of different stakeholders, and provide convincing argumentation that support technical solutions in mitigating risks. Our work recognizes the need of a solid and easy argumentative structure to provide evidences which support the privacy-awareness.</p>
<p>The <em>Privacy Management Reference Model and Methodology (PMRM)</em> <span class="citation">(“OASIS Privacy Management Reference Model (PMRM) TC” 2018)</span> is a proposal of the <em>Advancing Open Standards for the Information Society (OASIS)</em> which has high level guidelines to help business process engineers, IT analysts, architects, and developers in implementing privacy and security policies. By having a focus on policies, <em>PMRM</em> lacks guidelines on how to deal with many other important privacy concepts, such as user perceptions, utility tradeoffs, privacy techniques, metrics, and attacks.</p>
<p>Considering the related work, we can notice a lack of methodologies to guide the development and that considers important concepts like norms, perception studies, privacy techniques, trade-offs and attacks. Our novel proposed methodology considers such concepts and increases the confidence of the project through the provision of privacy evidences.</p>
