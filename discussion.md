[Back to index](https://pedroysb.github.io/Privacy-by-Evidence)

# Discussion

<p>The internet is connecting more devices every day and this growth carries several benefits. However, there are many concerns of privacy. For a company, being able to state that its product is “privacy-friendly” is a competitive advantage. When carrying forward the concern of privacy preserving, there are rules to follow and techniques to apply. Unfortunately, there is a lack of methodologies to guide the development, applying in practice the rules and privacy techniques.</p>
<p><em>Privacy by Design</em> (<em>PbD</em>) consists in 7 foundational principles to be followed when developing systems that should take into account users privacy. However, we concluded that these principles alone are not enough. They are still vague and leave many open questions on how to apply them in practice. In this work, we aimed to develop a generalizable methodology to fill this gap.</p>
<p>We identified the key concepts to be considered when dealing with privacy-friendly applications and described a conceptual framework, aiming to generate a manageable knowledge to be used in our proposed methodology. The concepts are: participants (users, project owner, development team, regulatory agency, privacy engineer, attacker and data recipient); application context; data formats; data sensitivity; privacy norms and legislation; users perception of privacy; privacy techniques; attacks; privacy models; data utility; and security.</p>
<p>We proposed the concept of <em>Privacy by Evidence</em> (<em>PbE</em>), a software development methodology to provide privacy-awareness. <em>PbE</em> is in accordance with all the 7 principles defined by <em>PbD</em>, and therefore, <em>PbE</em> may be considered as an extension of <em>PbD</em>. <em>PbE</em> consists in the execution of five activities in parallel with the development of the application. The activities are: identify the application context and data format; check compliance with norms and legislation; identify utilities and risk assessment; evaluate and apply privacy techniques; and evaluate potential attacks. Given the difficulty in providing total privacy (<em>i.e.</em>, free of vulnerabilities), we propose to document the mitigations in form of evidences, aiming to increase the confidence of the project. The evidences should be structured using the <em>Goal Structuring Notation</em> (<em>GSN</em>), a graphical argumentation notation that can be used to document explicitly the individual elements of any argument and, perhaps more significantly, the relationships that exist between these elements. Arguments documented using <em>GSN</em> can help to provide privacy assurance.</p>
<p>To validate the effectiveness of <em>PbE</em>, we conducted four case studies, executing the activities described here in smart energy metering, people counting, energy efficiency, and a two factor authentication applications. These are examples of applications that are growing in numbers, and their usage may bring privacy risks, causing many people and even the media to show distrust about them.</p>
<p>The main objective of these case studies were to assess the ability of <em>PbE</em> in producing evidences of privacy. In order to achieve this objective we defined four research questions using the <em>Goal, Question, Metric</em> (<em>GQM</em>) paradigm. To answer these four questions, we use the metrics of number of provided evidences and their sum of weights. For the smart energy metering application (LiteMe), using the <em>PbE</em>, the team was able to provide seven evidences of privacy, and the sum of their weights resulted in 28. For the people counting application (Pulso), the team provided five evidences and the sum of their weights resulted in 19. For the energy efficiency application (Lumen), the team provided five evidences, and the sum of their weights resulted in 19 too. For the two factor authentication, we used the Think Aloud protocol to observe the development process more closely. In this case study, the team provided four evidences of privacy, and the sum of their weights resulted 86. Therefore, we positively support all the four research questions (<span class="math inline"><em>R</em><em>Q</em>1</span>, <span class="math inline"><em>R</em><em>Q</em>2</span>, <span class="math inline"><em>R</em><em>Q</em>3</span> and <span class="math inline"><em>R</em><em>Q</em>4</span>) and claim that <em>PbE</em> is an effective way to develope privacy-friendly applications.</p>
<p>During the condution of the case studies, we had many lessons learned and received many feedbacks in order to improve the methodology. For example, the activity of “Identify Utilities and Risk Assessment” demonstrated to be hard and subjective. Therefore, the condution of privacy perception studies is a useful task to help in this activity and to identify and quantify privacy concerns. Another insight was that the activity of “Evaluate Potential Attacks” demonstrated to be important when developing privacy-friendly applications. The identification of working attacks in this activity and the need to return to previous activities in order to mitigate the risks indicate that without the attack evaluations, developers would just proceed to deployment/production phases. Another insight was that less experienced developers may confuse the concepts of security and privacy. This suggests that, before starting the development, it would be useful for the developers to have a small period of training regarding security, privacy, and their differences.</p>
<p>Based on the experience obtained from the analysis of the case studies, we concluded that all the artifacts presented in the checklist of Table [tab:checklist] are important. However, a minimal set of artifacts that we recommend would be the following: <em>Engagement Report, Summary of Norms, Privacy Concerns, Adversary Model, Summary of Techniques, Implementation of Techniques,</em> and <em>Summary of Attacks</em>. This minimal set was defined based on the need to maintain the usual workflow of <em>PbE</em> and to allow the privacy understanding and the actual state by the participants of the project.</p>
<p>A limitation of this work is that we did not conduct a quantitative experiment with a set development teams using <em>PbE</em> and another set of teams not using <em>PbE</em>. That experiment would provide results with statistical confidence regarding the effectiveness of <em>PbE</em> in developing privacy-friendly applications. Therefore, we leave the conduction of this experiment as a possible future work.</p>

[Back to index](https://pedroysb.github.io/Privacy-by-Evidence)
